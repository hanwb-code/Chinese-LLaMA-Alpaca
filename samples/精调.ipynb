{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#合并 chinese-alpaca-plus-lora-7b\n",
    "!cd Chinese-LLaMA-Alpaca && python scripts/merge_llama_with_chinese_lora.py \\\n",
    "    --base_model /home/llama/llama-dl/llama_7b_hf \\\n",
    "    --lora_model /home/llama/chinese-llama-plus-lora-7b,/home/llama/chinese-alpaca-plus-lora-7b \\\n",
    "    --output_type pth \\\n",
    "    --output_dir /home/llama/merge_alpaca_plus_lora_7b_pt\n",
    "\n",
    "#验证SHA256值  Chinese-Alpaca-Plus-7B 8b8f6551d0d83f93e378622b9f8dad0bec189da6c29d8a78de493e6aee9bd35f\n",
    "!sha256sum /home/merge_alpaca_plus_lora_7b_pt/consolidated.00.pth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Chinese-LLaMA-Alpaca/pt_data\n",
    "!cp Chinese-LLaMA-Alpaca/data/pt_sample_data.txt Chinese-LLaMA-Alpaca/pt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhrAVNUKSw9_",
    "outputId": "4f240f2b-2396-405b-9a94-84446db8d3e6"
   },
   "outputs": [],
   "source": [
    "#创建基于原模型扩充词表\n",
    "!cd Chinese-LLaMA-Alpaca/scripts/merge_tokenizer/ && python merge_tokenizers.py \\\n",
    "  --llama_tokenizer_dir /home/llama/llama-dl/llama_7b_hf \\\n",
    "  --chinese_sp_model_file /home/workspace/Chinese-LLaMA-Alpaca/scripts/merge_tokenizer/chinese_sp.model\n",
    "\n",
    "#训练模型\n",
    "!cd Chinese-LLaMA-Alpaca/scripts/training && torchrun --nnodes 1 --nproc_per_node 1 run_clm_pt_with_peft.py \\\n",
    "    --deepspeed ds_zero2_no_offload.json \\\n",
    "    --model_name_or_path /home/llama/llama-dl/llama_7b_hf \\\n",
    "    --tokenizer_name_or_path /home/workspace/Chinese-LLaMA-Alpaca/scripts/merge_tokenizer/merged_tokenizer_hf \\\n",
    "    --dataset_dir /home/workspace/Chinese-LLaMA-Alpaca/pt_data \\\n",
    "    --data_cache_dir data_cache \\\n",
    "    --validation_split_percentage 0.001 \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --do_train \\\n",
    "    --fp16 \\\n",
    "    --seed $RANDOM \\\n",
    "    --max_steps 100 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --learning_rate 2e-4 \\\n",
    "    --warmup_ratio 0.05 \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --logging_strategy steps \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_strategy steps \\\n",
    "    --save_total_limit 3 \\\n",
    "    --save_steps 50 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --preprocessing_num_workers 8 \\\n",
    "    --block_size 512 \\\n",
    "    --output_dir /home/workspace/Chinese-LLaMA-Alpaca/output_model \\\n",
    "    --overwrite_output_dir \\\n",
    "    --ddp_timeout 30000 \\\n",
    "    --logging_first_step True \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 32\\\n",
    "    --trainable q_proj,v_proj,k_proj,o_proj,gate_proj,down_proj,up_proj \\\n",
    "    --modules_to_save embed_tokens,lm_head \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --torch_dtype float16 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --ddp_find_unused_parameters False\n",
    "\n",
    "#或使用脚本训练模型\n",
    "!cd Chinese-LLaMA-Alpaca/scripts/training && ./run_pt.sh\n",
    "\n",
    "#合并模型\n",
    "!cd Chinese-LLaMA-Alpaca && python scripts/merge_llama_with_chinese_lora.py \\\n",
    "    --base_model /home/llama/llama-dl/llama_7b_hf \\\n",
    "    --lora_model /home/workspace/Chinese-LLaMA-Alpaca/output_model/pt_lora_model \\\n",
    "    --output_type huggingface \\\n",
    "    --output_dir /home/workspace/Chinese-LLaMA-Alpaca/output_model/hf_lora_model\n",
    "\n",
    "#启动原训练合并后的hf模型演示\n",
    "!python scripts/inference/inference_hf.py --base_model /home/workspace/Chinese-LLaMA-Alpaca/output_model/hf_lora_model --with_prompt --interactive --gpus 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#启动模型demo\n",
    "!python scripts/inference/inference_hf.py --base_model /home/llama/merge_alpaca_plus_lora_7b_hf --with_prompt --interactive --gpus 0\n",
    "\n",
    "#启动web demo\n",
    "!python scripts/inference/gradio_demo.py --base_model /home/llama/merge_alpaca_plus_lora_7b_hf --gpus 0"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
